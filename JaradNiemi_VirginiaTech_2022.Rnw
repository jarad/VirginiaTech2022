\documentclass[10pt,aspectratio=169,handout]{beamer}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{pdfpages}
\usepackage{tikz}
\usepackage[ruled,vlined,linesnumbered,resetcount]{algorithm2e}

% \includeonlyframes{current}

\usetheme{AnnArbor}
\usecolortheme{beaver}

\definecolor{Cardinal}{RGB}{200,16,46}

% \usetikzlibrary{arrows.meta,positioning}

\graphicspath{{include/}}

\usepackage[export]{adjustbox}

\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

% to avoid counting all pages
\newcommand{\backupbegin}{
   \newcounter{finalframe}
   \setcounter{finalframe}{\value{framenumber}}
}
\newcommand{\backupend}{
   \setcounter{framenumber}{\value{finalframe}}
}

\newcommand{\transitionslide}[1]{
{
% \setbeamertemplate{navigation symbols}{} 
\setbeamercolor{background canvas}{bg=Cardinal}
\setbeamercolor{normal text}{fg=white}
\usebeamercolor[fg]{normal text}
\begin{frame}[plain]

\begin{center}
{\Huge #1}
\end{center}

\end{frame}
}
}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{itemize items}[default]
% \setbeamertemplate{itemize subitem}{\alph{enumii}.}
% \setbeamertemplate{itemize subsubitem}{\roman{enumiii}.}
\setkeys{Gin}{width=0.6\textwidth}

% Reference and link colors
\hypersetup{
  colorlinks  = false,
  linkcolor   = blue,
  urlcolor    = blue,
  citecolor   = blue,
  anchorcolor = blue
}

% Math commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\ind}{\stackrel{ind}{\sim}}
\providecommand{\ov}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\text{\b{$#1$}}}

\usefonttheme[onlymath]{serif} % uncomment for article style math

\institute[ISU]{Iowa State University}
\date{\today}

\title{Toward Statistical Emulators of Agricultural Computer Models}
\author{Jarad Niemi}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA,
               fig.width=9, fig.height=5,
               size='normalsize',
               out.width='0.8\\textwidth',
               fig.align='center',
               message = FALSE,
               echo = FALSE,
               cache = TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library("tidyverse")
library("mvtnorm")
@

<<set_seed, echo=FALSE>>=
set.seed(20210611)
@

\begin{document}

% JN ---------------------------------------------------------------------------

\begin{frame}

  \maketitle
  \vspace{0.2in} \pause

  {\footnotesize
    Funded, in part, by
    \begin{itemize}
      \item[-] the Iowa State University Presidential Interdisciplinary
      Research Initiative on C-CHANGE: Science for a Changing Agriculture
      \item[-] USDA NIFA: \href{https://cris.nifa.usda.gov/cgi-bin/starfinder/0?path=fastlink1.txt&id=anon&pass=&search=R=88415&format=WEBLINK}{Consortium for Cultivating Human And Naturally reGenerative Enterprises (C-CHANGE Grass2Gas)}
      \item[-] Foundation for Food and Agriculture Research: \href{https://foundationfar.org/2019/04/01/ffar-grant-improves-soil-health-and-increases-farm-sustainability/}{Prairie Strips for Healthy Soils and Thriving Farms}
    \end{itemize}
  }

\end{frame}



\begin{frame}
\frametitle{Collaborators}
Prairie STRIPS Collaborators: \url{http://prairiestrips.org/people}

\vspace{0.2in} \pause

Gaussian Process Emulators:

\vspace{0.2in}

\begin{columns}
\begin{column}{0.24\textwidth}
\includegraphics[width=0.7\textwidth]{ben_neo} \pause
\end{column}
\begin{column}{0.24\textwidth}
\adjincludegraphics[trim = {{.2\width} 0 {.2\width} {.2\height}}, clip, width=0.7\textwidth]{nate_garton}
\end{column}
\begin{column}{0.24\textwidth}
\includegraphics[width=0.7\textwidth]{alicia_carriquiry} \pause
\end{column}
\begin{column}{0.24\textwidth}
\includegraphics[width=0.7\textwidth]{luis_damiano}
\end{column}
\end{columns}

\end{frame}


\section{Effects of agriculture}
\transitionslide{Agriculture}

\begin{frame}
\frametitle{Corn Belt}

\includegraphics[width=\textwidth]{iowa-corn}

{\tiny \url{https://www.rma.usda.gov/en/RMALocal/Iowa}}
\end{frame}


\subsection{Production}
\begin{frame}
\frametitle{Iowa Agricultural Production}

{\tiny \url{https://www.iadg.com/iowa-advantages/target-industries/}}

\begin{quote}
Iowa is the largest producer of corn, pork and eggs in the United States and
second in soybeans and red meat production.
\end{quote}

\vspace{0.2in}

\includegraphics[height=0.3\textheight, width=0.19\textwidth, trim = 0 0 0 50, clip]{corn}
\includegraphics[height=0.3\textheight, width=0.19\textwidth, trim = 0 0 250 0, clip]{hogs}
\includegraphics[height=0.3\textheight, width=0.19\textwidth]{eggs}
\includegraphics[height=0.3\textheight, width=0.19\textwidth]{soybeans}
\includegraphics[height=0.3\textheight, width=0.19\textwidth, trim = 0 100 0 100, clip]{cows}

\vspace{0.2in}

{\tiny
\url{https://www.britannica.com/plant/corn-plant}

\url{https://www.nationalhogfarmer.com/marketing/total-pork-production-2014-down-slightly}

\url{https://www.medicalnewstoday.com/articles/283659}

\url{https://www.midwestfarmreport.com/2019/12/11/state-soybean-yield-contest-entries-announced/}

\url{https://www.scientificamerican.com/article/meat-and-environment/}
}

\end{frame}



\begin{frame}
\frametitle{Agriculture Impact on Climate Change}

\includegraphics[width=0.5\textwidth]{GHG2022inset}

{\tiny \url{https://www.ers.usda.gov/topics/natural-resources-environment/climate-change/}}
\end{frame}







% 
% 
% 
% \begin{frame}[t]
% \frametitle{Corn production}
% \includegraphics[width=0.49\textwidth]{farmland}
% \includegraphics[width=0.49\textwidth]{corn_yield}
% 
% {\tiny \url{https://www.iowaagliteracy.org/Article/Family-Farms-Then-and-Now}}
% 
% {\tiny \url{https://extension.entm.purdue.edu/newsletters/pestandcrop/article/historical-corn-grain-yields-in-the-u-s/}}
% \end{frame}
% 

\subsection{Dead zone}
\begin{frame}
\frametitle{Gulf of Mexico Dead Zone}
\setkeys{Gin}{width=0.9\textwidth}

\includegraphics{dead_zone}

{\tiny \url{https://www.noaa.gov/media-release/gulf-of-mexico-dead-zone-is-largest-ever-measured}}
\end{frame}


\subsection{Soil loss}
\begin{frame}
\frametitle{Soil loss}

Iowa loses \$1,000,000,000/year in soil

\vspace{0.2in}

\includegraphics[width=0.7\textwidth]{soil_loss}

{\tiny
\url{https://www.desmoinesregister.com/story/money/agriculture/2014/05/03/erosion-estimated-cost-iowa-billion-yield/8682651/}
}

\end{frame}


% 
% 
% 
% 
% % \subsection{Des Moines Water Works Lawsuit}
% % \begin{frame}
% % \frametitle{Des Moines Water Works Lawsuit}
% % \setkeys{Gin}{width=0.7\textwidth}
% % 
% % \includegraphics{des_moines_water_works_lawsuit}
% % 
% % {\tiny \url{https://www.lwvumrr.org/blog/des-moines-water-works-lawsuit-update}}
% % 
% % \end{frame}
% 
% 
% 
% 
\section{C-CHANGE}
\transitionslide{C-CHANGE}


\begin{frame}[t]
\frametitle{C-CHANGE: Science for a changing agriculture}

\begin{columns}[T]
\begin{column}{0.35\textwidth}
\includegraphics[width=\textwidth]{cchange}
\url{http://agchange.org} \pause
\end{column}
\begin{column}{0.45\textwidth}
Prairie STRIPS

C-CHANGE PIRI

C-CHANGE Grass2Gas

Climate Smart Ag
% \begin{itemize}
% \item Prairie STRIPS
% \item C-CHANGE PIRI
% \item C-CHANGE Grass2Gas
% \item Climate Smart Ag
% \end{itemize}
\end{column}
\end{columns}
\end{frame}


\begin{frame}[t]
\frametitle{Prairie STRIPS in Conservation Reserve Program}

\only<2->{
\includegraphics[width=0.8\textwidth]{pnas_title}
}

\vspace{0.1in}

\begin{columns}
\begin{column}{0.5\textwidth}
\vspace{0pt}
\adjincludegraphics[trim={0 0 0 {.2\height}}, clip, width=\textwidth]{strips_field}
\end{column}
\begin{column}{0.5\textwidth}
\vspace{0pt}
\only<3->{
\includegraphics[width=\textwidth]{cp-43}
}
\end{column}
\end{columns}
\end{frame}




% 
% 
% \subsection{STRIPS1}
% \begin{frame}
% \frametitle{STRIPS1 - Neal Smith National Wildlife Refuge}
% \begin{columns}
% \begin{column}{0.5\textwidth}
% \adjincludegraphics[trim={{.4\width} 0 0 {.57\height}}, clip, width=\textwidth]{map}
% \href{https://www.google.com/maps/place/Neal+Smith+National+Wildlife+Refuge/@41.5475331,-93.2686897,3219m/data=!3m1!1e3!4m5!3m4!1s0x87eee81ce3a71817:0xc745a0b0aed9e495!8m2!3d41.5652684!4d-93.2766143}{Find on Google Maps} \pause
% \end{column}
% \begin{column}{0.5\textwidth}
% \includegraphics[width=\textwidth]{treatments}
% 
% \vspace{0.5in} \pause
% 
% \includegraphics[width=\textwidth]{design}
% \end{column}
% \end{columns}
% \end{frame}
% 
% 
% \begin{frame}[t]
% \frametitle{STRIPS1 - Science}
% \begin{columns}
% \begin{column}{0.6\textwidth}
% \onslide<2->{\includegraphics[width=\textwidth]{strips_overview}}
% \vspace{0.1in}
% \end{column}
% \begin{column}{0.4\textwidth}
% \onslide<3->{\includegraphics[width=\textwidth]{flumes}}
% \end{column}
% \end{columns}
% \end{frame}
% 
% 
% \begin{frame}
% \frametitle{STRIPS1 - PNAS}
% \adjincludegraphics[trim={0 {.785\height} 0 0}, clip, width=\textwidth]{pnas_fig}
% 
% \pause
% 
% \adjincludegraphics[trim={0 0 0 {.653\height}}, clip, width=\textwidth]{pnas_fig}
% \end{frame}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 

\subsection{Daily Erosion Project}
\begin{frame}
\frametitle{Daily Erosion Project (DEP)}
\framesubtitle{using Water Erosion Prediction Project (WEPP)}

\includegraphics[width=0.49\textwidth,trim={0 0 0 2.5cm},clip]{dep_precip}
\includegraphics[width=0.49\textwidth,trim={0 0 0 2.5cm},clip]{dep_soil_loss}

\end{frame}



\subsection{WEPP}
\begin{frame}
  \frametitle{Water Erosion Prediction Project (WEPP)}

  \begin{figure}
      \begin{center}
          \includegraphics[width=\textwidth,height=0.8\textheight,keepaspectratio]{wepp}
      \end{center}
  \end{figure}
\end{frame}



\subsection{WEPPR}
\begin{frame}[fragile]
\frametitle{WEPPR}
R packages:
\begin{itemize}
\item {\tt WEPPR}: R interface for WEPP computer model
\item {\tt DEPR}: R interface for DEP/WEPP computer model
\item {\tt WEPPemulator}: utility features for emulator construction
\end{itemize}

\vspace{0.1in}

<<WEPPRplots, echo=TRUE, eval=FALSE>>=
library("WEPPR")
library("tidyverse")
library("gridExtra")

slp <- read_slp(system.file("extdata", "071000090603_2.slp", package="WEPPR"))
cli <- read_cli(system.file("extdata", "092.63x040.90.cli", package="WEPPR"))

grid.arrange(plot(slp, plots="slope"), 
             plot(slp, plots="elevation"), 
             plot(cli), 
             layout_matrix = rbind(1:2,3))
@
\end{frame}


\begin{frame}
\frametitle{WEPPR Plots}
<<echo=FALSE>>=
<<WEPPRplots>>
@
\end{frame}

\begin{frame}[fragile]
\frametitle{WEPPR Plots}

\vspace{-0.2in}

<<echo=TRUE,fig.height=4>>=
sol <- read_sol(system.file("extdata", "071000090603_2.sol", package="WEPPR"))
plot(merge_slp_sol(slp,sol))
@
\end{frame}


\transitionslide{GP Emulators}
\section{GP Emulators}
\begin{frame}
\frametitle{Gaussian Process (GPs)}
Consider a deterministic computer model $f(\cdot)$ with
\[
Y_i
% = f(X_i, \psi)
= f(X_i), \quad i=1,\ldots,N
\]

\pause 
where
\begin{itemize}
% \item $\psi$ are model parameters,
\item $X_i$ are inputs and
\item $Y_i$ are outputs with $Y = (Y_1,\ldots,Y_N)$.
\end{itemize}

\pause

We assume a Gaussian Process prior
\[ f \sim \mathcal{GP}\left(m, k \right) \pause \implies Y \sim N(m_x, \Sigma) \]
\pause
where (often) $m_x = 0$ \pause and, for scalar inputs,
$\Sigma_{ij} = k(x_i,x_j) = \sigma^2 e^{-(x_i-x_j)^2/\phi}$.

\vspace{0.1in} \pause

Two research directions:
\begin{itemize}
\item Computational tractability for large $N$
\item Dealing with functional inputs
\end{itemize}
\end{frame}




\subsection{Training a GP}
\begin{frame}
\frametitle{Training a GP}

Find the maximum likelihood estimator (MLE) for
$\theta = (\sigma^2,\phi)$, \pause

\[
\hat{\theta} = \mbox{argmax}_\theta \, p(y|\theta)
= \mbox{argmax}_{\theta} \, N\left(y; 0, \Sigma(\theta)\right)
\]

where $y=(y_1,\ldots,y_N)$.

\vspace{0.2in} \pause

The log-likelihood is
\[
\log \mathcal{N}(y; 0, \Sigma(\theta)) \propto C
- \log |\Sigma(\theta)|
- y^\top \Sigma(\theta)^{-1} y
\]

\pause

If there are $N$ observations,
$\Sigma(\theta)$ is an $N\times N$ covariance matrix \pause
and thus the computational time scales as $\mathcal{O}(N^3)$.

\vspace{0.2in} \pause

This is doable if $N\approx 1,000$ but not when you start getting larger
and larger data sets.
% ?? Gaussian Processes Meets Big Data
\end{frame}






\subsection{Sparse GPs using knots}
\begin{frame}
\frametitle{Fully Independent Conditional (FIC) Approximation}

Introduce a set of knots $x^{\dagger} = \left\{x_1^\dagger, \ldots, x_K^\dagger \right\}$ with $K<<N$,
\pause
such that
\[
p(f_x,f_{x^{\dagger}}|\theta) = p(f_x|f_{x^{\dagger}}, \theta) p(f_{x^{\dagger}}|\theta)
\]
\pause
where
\[ \begin{array}{rl}
f_{x^{\dagger}}| \theta &\sim  \mathcal{N}(0, \Sigma_{x^{\dagger}x^{\dagger}}) \pause \\
f_x| f_{x^{\dagger}} , \theta  &\sim  \mathcal{N}\left(\Sigma_{xx^{\dagger}} \Sigma_{x^{\dagger}x^{\dagger}}^{-1}(f_{x^{\dagger}}) , \Lambda \right)
\end{array} \]
\pause
with $\Lambda = \text{diag}\left(\Sigma_{xx} - \Sigma_{x x^{\dagger}} \Sigma_{x^{\dagger}x^{\dagger}}^{-1} \Sigma_{x^{\dagger}x}\right)$.

\vspace{0.2in} \pause

This joint implies the following marginal distribution for $f_x$:
\[
f_x| \theta \sim \mathcal{N}(0, \Lambda + \Sigma_{x x^{\dagger}} \Sigma_{x^{\dagger}x^{\dagger}}^{-1} \Sigma_{x^{\dagger}x})
\]
\pause
which has the correct marginal means and variances,
but the covariances are controlled by the knots.

\vspace{0.1in} \pause

{\tiny
\citep{seeger2003, candela2005, snelson2006, banerjee2008, finley2009, titsias2009, cao2013}
}

\end{frame}


\begin{frame}
\frametitle{Train FIC Model}

Let $\Psi(x^\dagger, \theta) \equiv \Lambda(\theta) + \Sigma_{x x^{\dagger}}(\theta) \Sigma_{x^{\dagger}x^{\dagger}}(\theta)^{-1}\Sigma_{x^{\dagger}x}(\theta)$,
then
\[
Y|x^{\dagger}, \theta\sim \mathcal{N}(0, \Psi(x^\dagger, \theta) ).
\]

\vspace{0.2in} \pause

Train the model by finding
\[
\hat{x}^\dagger,\hat\theta = \mbox{argmax}_{x^\dagger,\theta} \mathcal{N}(y; 0, \Psi(x^\dagger, \theta)).
\]
\pause
which has computational complexity of $\mathcal{O}(NK^2)$.
\vspace{0.2in} \pause

There are a number of questions:
\begin{itemize}
\item how many knots are needed?
\item where should the knots be?
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Simultaneous knot optimization}
\setkeys{Gin}{width=0.7\textwidth}
{\tiny (this has a nugget)}
\includegraphics{normal_example}
\end{frame}



\begin{frame}
\frametitle{Adding another knot}
\setkeys{Gin}{width=0.7\textwidth}
\includegraphics{normal_marginal_ll}
\end{frame}




\transitionslide{OAT Algorithm}
\section{One-at-a-time (OAT) selection}
\begin{frame}
\frametitle{Knot selection algorithm}

Algorithm 1. OAT knot selection algorithm. Convergence in the repeat loop is declared when the change in the objective function, the log-marginal likelihood, falls below a threshold. Set initial number of knots ($K_I$).

\pause

\begin{algorithm}[H]
\SetAlgoLined
\textbf{Initialize:} $x^{\dagger} = \{x^{\dagger}_i \}_{i = 1}^{K_{I}}$ \pause \;
$\hat{\theta} = \mbox{argmax}_{\theta} p(y|x, x^{\dagger}, \theta)$ \pause \;
\Repeat{$|x^{\dagger}| = K_{max}$ or convergence}{
propose new knot $x^{\dagger^*} \leftarrow J(y , x, x^{\dagger}, \hat{\theta})$ \pause \;
$(\hat{x}^{\dagger^*}, \hat{\theta}) = \mbox{argmax}_{(x^{\dagger^*}, \theta)} p(y|x, \{x^{\dagger}, x^{\dagger^*}\}, \theta)$ \pause \;
$x^{\dagger} = \{x^{\dagger}, \hat{x}^{\dagger^*}\}$ \;
}
\end{algorithm}
\end{frame}




\begin{frame}
\frametitle{Bayesian optimization}

Let 
\begin{itemize}
\item $w_{1:t-1}$ be the vector of log-marginal likelihood values at the candidates for the knot proposal which have thus far been explored at time $t$ and
\item $w^{+} = \max(w_{1:t-1})$.
\end{itemize}

\vspace{0.1in} \pause

Let $W(z)$ be the unknown marginal likelihood at input location $z$ 
\pause 
and model it using a GP, for clarity call this the \alert{meta GP}.

\vspace{0.2in} \pause

Then expected improvement is 
{\small
\[
\begin{array}{ll}
% \alpha \left(z;w_{1:t-1}, \left\{x_1^\dagger,\ldots,x_{t-1}^\dagger\right\} \right) 
\alpha\left(z;x_{1:t-1}^\dagger,w_{1:t-1}\right) = E[\max(W(z)-w^+,0)]
= & (E\left[W(z)|w_{1:t-1}\right] - w^{+})\Phi\left(\frac{E\left[W(z)|w_{1:t-1}\right] - w^{+}}{\sqrt{ V\left[W(z)|w_{1:t-1} \right] } } \right) \\
& + \sqrt{ V\left[W(z)|w_{1:t-1}\right] }\phi \left(\frac{E\left[W(z)|w_{1:t-1}\right] - w^{+}}{\sqrt{ V\left[W(z)|w_{1:t-1}\right] } } \right).
\end{array}
\]
}
where $\phi$ and $\Phi$ are the pdf and cdf of a standard normal, respectively.

\vspace{0.1in} \pause

{\tiny
\citep{jones2001, shahriari2016}
}

\end{frame}



\begin{frame}
\frametitle{Knot proposal algorithm}

Algorithm 2. Knot proposal algorithm.
Set the minimum ($T_{min}$) and maximum ($T_{max}$) number of marginal
likelihood evaluations.

\pause

{\small
\begin{algorithm}[H]
\SetAlgoLined
set the mean of the meta GP equal to 
$\log p\left(y\left|x,\left\{x^{\dagger},\cdot\right\}, \hat{\theta}\right.\right)$ \pause \;
sample $x_1^\dagger, ..., x^\dagger_{T_{min}}$ without replacement from $x$ \pause \;
% $\{ x_i \}_{i = 1}^{n}$ \;

% $z \leftarrow \{z_1, ..., z_{T_{min}} \} \cup x^{\dagger} $ \;
augment known marginal likelihood values 
$w_j = \log p\left(y\left|x,\left\{x^{\dagger},x^{\dagger}_j\right\}, \hat{\theta}\right.\right)$ for $j=1,\ldots,k$ 
with evaluations of the marginal likelihood at the new knots, 
that is $w_{k+j} = \log p\left(y\left|x, \left\{x^{\dagger},x^\dagger_j\right\}, \hat{\theta}\right.\right)$ for $j = 1,...,T_{min}$ \pause \;
% $t \leftarrow T_{min}$ \;
% \jarad{don't need to set this here because it is set in the loop}
\For{$t = T_{min}+1, ..., T_{max}$}{
update covariance parameters in meta GP \pause \;
$x^*_t = \mbox{argmax}_{z \in x \setminus x^{\dagger}_{1:t-1}} \alpha\left(z;x_{1:t-1}^\dagger,w_{1:t-1}\right)$ \pause \;
$w_t = \log p\left(y\left|x, \left\{x^{\dagger}, x^*_t \right\}, \hat{\theta}\right.\right)$ \pause \;
}
return $x_j^*$ such that $j=\mbox{argmax}_t \, w_t$
\end{algorithm}
}
\end{frame}


\begin{frame}
\frametitle{Knot selection algorithm}

Algorithm 1. OAT knot selection algorithm. Convergence in the repeat loop is declared when the change in the objective function, the log-marginal likelihood, falls below a threshold. Set 
initial number of knots ($K_I$).

\begin{algorithm}[H]
\SetAlgoLined
\textbf{Initialize:} $x^{\dagger} = \{x^{\dagger}_i \}_{i = 1}^{K_{I}}$  \;
$\hat{\theta} = \mbox{argmax}_{\theta} p(y|x, x^{\dagger}, \theta)$  \;
\Repeat{$|x^{\dagger}| = K_{max}$ or convergence}{
propose new knot $x^{\dagger^*} \leftarrow J(y , x, x^{\dagger}, \hat{\theta})$ \;
$(\hat{x}^{\dagger^*}, \hat{\theta}) = \mbox{argmax}_{(x^{\dagger^*}, \theta)} p(y|x, \{x^{\dagger}, x^{\dagger^*}\}, \theta)$ \;
$x^{\dagger} = \{x^{\dagger}, \hat{x}^{\dagger^*}\}$ \;
}
\end{algorithm}
\end{frame}



% \begin{frame}
% \frametitle{One-D Gaussian data}
% \setkeys{Gin}{width=\textwidth}
% \includegraphics[width=0.7\textwidth]{oat_vs_simult_gaussian_example}
% 
% Starting locations: evenly spaced (left), adversarial (middle), random (right)
% 
% Algorithm: OAT (top) and simultaneous (bottom)
% 
% \end{frame}
% 
% 
% \begin{frame}
% \frametitle{Computational results}
% \begin{tabular}{|l|l|r|r|r|r|r|}
% \hline
% Method & Initialization & K & RMSE & Runtime & GA Steps & log-Likelihood\\
% \hline
% Full GP & -- & -- & 0.192 & -- & -- & -311.720\\
% \hline
% OAT & Uniform & 13 & 0.180 & 50 & 464 & -308.120\\
% \hline
% OAT & Adversarial & 22 & 0.228 & 96 & 669 & -308.587\\
% \hline
% OAT & Random & 13 & 0.228 & 50 & 470 & -308.225\\
% \hline
% Simult. & Uniform & 13 & 0.220 & 140 & 212 & -306.852\\
% \hline
% Simult. & Adversarial & 22 & 0.196 & 700 & 529 & -308.398\\
% \hline
% Simult. & Random & 13 & 0.247 & 88 & 140 & -308.071\\
% \hline
% \end{tabular}
% \end{frame}


\subsection{Applications}
\begin{frame}
\frametitle{Performance metrics}

All data models:
\[ 
MNLP = \text{median}_{i \in 1, ..., N_{test}} \{ -\log p(\tilde{y}_i|x^{\dagger}, \hat{\theta}, y) \}.
\]

\vspace{0.2in}

\[ 
AUKL = \frac{1}{N_{test}} \sum_{i = 1}^{N_{test}}\int p_{full}(f(\tilde{x}_i)|\hat{\theta}, y) \log \frac{p_{full}(f(\tilde{x}_i)|\hat{\theta}, y)}{p_{sparse}(f(\tilde{x}_i)|x^{\dagger}, \hat{\theta}, y)} df(\tilde{x}_i).
\]

\vspace{0.2in} \pause

Gaussian:
\[ SRMSE = \sigma_{\tilde{y}}^{-1} \sqrt{ \frac{1}{N_{test}} \sum_{i = 1}^{N_{test}} (E\left[f(\tilde{x}_i)|Y\right] - \tilde{y}_i )^2}, \]
where $\sigma_{\tilde{y}}^2 = \frac{1}{N_{test} - 1}\sum_{i = 1}^{N_{test}}(\tilde{y}_i - \ubar{\tilde{y}})^2$, $\ubar{\tilde{y}} = \frac{1}{N_{test}} \sum_{i = 1}^{N_{test}}\tilde{y}_i$, and $\tilde{y}$ is the vector of test set target values.
\end{frame}



\subsection{Boston Housing}
\begin{frame}
\frametitle{Boston Housing}

490 observations (random 80\% for training) with $d=3$

\vspace{0.2in} 

\begin{table}
\centering
\begin{tabular}{|l|r|r|l|r|r|r|}
\hline
Method & Runtime & K & Tmax & SRMSE & MNLP & AUKL\\
\hline
Full & 394 & -- & -- & 0.359 & 2.500 & 0.000\\
\hline
OAT-BO & 545 & 13 & 25 & 0.366 & 2.466 & 0.045\\
\hline
OAT-RS & 356 & 12 & 25 & 0.366 & 2.464 & 0.039\\
\hline
OAT-RS & 339 & 15 & 50 & 0.364 & 2.469 & 0.047\\
\hline
Simult. & 25831 & 50 & -- & 0.378 & 2.291 & 0.356\\
\hline
Simult. & 3945 & 13 & -- & 0.356 & 2.313 & 0.242\\
\hline
\end{tabular}
\end{table}
\end{frame}


\begin{frame}
\frametitle{Banana Data}

5,300 binary observations (10\% training) with $d=2$

\vspace{0.2in} 

\begin{table}
\centering
\begin{tabular}{|l|r|l|r|r|r|}
\hline
Method & Runtime & Tmax & K & MNLP & AUKL\\
\hline
Full & 26795 & -- & -- & 0.038 & 0.000\\
\hline
OAT-BO & 3150 & 25 & 50 & 0.037 & 0.061\\
\hline
OAT-RS & 2954 & 25 & 50 & 0.038 & 0.051\\
\hline
OAT-RS & 3471 & 50 & 50 & 0.038 & 0.039\\
\hline
Simult. & 6219 & -- & 50 & 0.069 & 3.265\\
\hline
\end{tabular}
\end{table}
\end{frame}



\begin{frame}
\frametitle{Lansing Woods Hickory Data}

2,251 Poisson process observations with $d=2$

\vspace{0.2in} 

\begin{table}
\centering
\begin{tabular}{|l|r|r|l|r|r|}
\hline
Type & Runtime & K & Tmax & MNLP & AUKL\\
\hline
Full & 5892 & -- & -- & 1.040 & 0.000\\
\hline
OAT-BO & 846 & 28 & 25 & 1.058 & 0.321\\
\hline
OAT-RS & 1083 & 33 & 25 & 1.066 & 0.276\\
\hline
OAT-RS & 989 & 30 & 50 & 1.055 & 0.279\\
\hline
Simult. & 18456 & 50 & -- & 1.068 & 0.597\\
\hline
Simult. & 15046 & 28 & -- & 1.060 & 0.426\\
\hline
\end{tabular}
\end{table}
\end{frame}



\subsection{One-at-a-time (OAT) selection}
\begin{frame}
\frametitle{One-at-a-time (OAT) selection}
We developed a \alert{one-at-a-time (OAT) knot selection} that
\begin{itemize}
\item Begins with a small number of knots
\item Optimizes the knot locations according to the marginal likelihood or variational objective function
\item Iteratively adds knots until no improvement is seen in the objective function
\end{itemize}

\vspace{0.2in} \pause

Summary of results:
\begin{itemize}
\item Prediction is equivalent to Full GP and simultaneous knot optimization
\item Formally, OAT has computational complexity of $\mathcal{O}(NK^2)$
\item Practically, OAT is much faster than Full GP (on large data sets) and simultaneous knot optimization
\end{itemize}

\vspace{0.2in} \pause

Manuscripts:
\begin{itemize}
\item Nate Garton, Jarad Niemi, and Alicia Carriquiry. (2020) ``\href{https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11459}{Knot Selection in Sparse Gaussian Processes with a Variational Objective.}’’ Statistical Analysis and Data Mining. 13(4): 324-336.
\item Nate Garton, Jarad Niemi, and Alicia Carriquiry. ``\href{https://arxiv.org/abs/2002.09538}{Knot Selection in Sparse Gaussian processes.}’’ arXiv:2002.09538
\end{itemize}

\end{frame}


\transitionslide{Functional inputs}

\begin{frame}[label=current]
\frametitle{Vector-input Gaussian Process (viGP)}

For observation $i$, we have response $Y_i \in \R$ and
input $X_i = (X_{i,1},\ldots,X_{i,D})$.
\pause
Our deterministic computer model is $f()$ with $Y_i = f(X_i)$.

\vspace{0.1in} \pause

Assume $f$ is a zero-mean Gaussian process such that 
\[ Cor(Y_i,Y_j) = e^{-\frac{1}{2} D(X_i, X_j, \omega)} \]
\pause
and
\[
D(X_i, X_j, \omega) = \sum_{d = 1}^{D}{\omega_d (x_{i, d} - x_{j, d})^2}.
\]
Some refer to this as \alert{automatic relevance determination}.
\end{frame}




\begin{frame}[label=current]
  \frametitle{Functional-input Gaussian Process}

For observation $i$, we have $Y_i \in \R$ and $X_i(t)$ for $t \in [0,T]$.
\pause
Our computer model is $f: \mathcal{X} \to \R$ with $Y_i = f(X_i(t))$.

\vspace{0.1in} \pause

Following \cite{morris2012,morris2018}, the functional-input Gaussian Process has

\[ Cor(Y_i,Y_j) = e^{-\frac{1}{2} D(X_i(t), X_j(t), \omega)} \]
\pause
\[ D(X_i, X_j, \omega) = \int_0^T \omega(t) (X_i(t) - X_j(t))^2 dt \pause
\approx \sum_{d=1}^D \omega(t_d) (X_i(t_d) - X_j(t_d))^2. \]
\pause

We'll refer to this as \alert{fiGP} with
\alert{automatic dynamic relevance determination}.

\vspace{0.2in} \pause

For the \alert{functional length-scale},
one option is the asymmetric double exponential function
\begin{align*}
  \omega(t)
  =
    \begin{cases}
      \text{exp}\left(- \lambda_1 \ \lvert t - \tau \rvert
      \right) & \text{for } t \le \tau \\
      \text{exp}\left(- \lambda_2 \ \lvert t - \tau \rvert
      \right) & \text{for } t > \tau \\
    \end{cases}
\end{align*}
\end{frame}








\begin{frame}[label=current]
  \frametitle{Theoretical fiGP functional length-scale}

  \begin{figure}
      \begin{center}
          \includegraphics[width=\textwidth,height=0.8\textheight,keepaspectratio]{02-alf-weight-plot}
      \end{center}
  \end{figure}
\end{frame}


\begin{frame}[label=current]
  \frametitle{Case study}
  \framesubtitle{Implementation}

  \begin{itemize}
  \item 8 training and 8 test complementary sets JPL MLS data with 1,000 soundings each \pause
  \item 7 plausible models \pause
    \begin{itemize}
    \item viGP SE, ARD, FPCA, FFPCA
    \item fiGP Edn, SDE, ADE
    \item One model fit separately per input-output pair
    \end{itemize}
  \item Fully Bayesian inference
    \begin{itemize}
    \item Hamiltonian Monte Carlo~\citep[ch. 5]{brooks2011}
    \item NUTS algorithm~\citep{hoffman2014} via Stan~\citep{standevelopmentteam2021}
    \item 1 long chain~\citep{raftery1992}
    \item Extensive search for an initial value
    \item 500 post-warmup iterations
    \item 1,500 posterior samples
    \end{itemize}
  \item Several out-of-sample validation statistics
  \end{itemize}
\end{frame}


\begin{frame}[label=current]
\frametitle{Validation statistics}



\begin{table}
  \adjustbox{width=.79\textwidth,center}{%
    \centering
    \begin{tabular}{lrrrrr|r}
      \toprule
      \input{inc/validation-statistics-RMSE}
    \end{tabular}
    \begin{tabular}{lrrrrr|r}
      \toprule
      \input{inc/validation-statistics-PPLD}
    \end{tabular}}
  \caption{Mean validation statistics
    $\bar{v}^{(p, q)}$: RMSE (left) and negPPLD (right).
    Smaller values are better. Bold is best in class.
    % Note that $\EE{y}\approx 0$ and $\VV{y}\approx 1$.
  }%
  \label{tab:validation-statistics-mini}
\end{table}
\end{frame}


\begin{frame}[label=current]
  \frametitle{Estimated fiGP functional length-scale}

  \begin{figure}
      \begin{center}
          \includegraphics[width=\textwidth,height=0.8\textheight,keepaspectratio]{weights-all}
      \end{center}
  \end{figure}
\end{frame}


\begin{frame}[label=current]
  \frametitle{Summary}

  Research/policy advances
  \begin{itemize}
  \item Prairie strips impact on agroecosystem services and inclusion in CRP as CP-43
  \item OAT algorithm for knot selection to deal with computational intractability due to large $n$
  \item fiGP/ADRD model for functional inputs
  \end{itemize}

  \vspace{0.1in} \pause

  These slides are available at
  \begin{itemize}
    \item \url{https://github.com/jarad/VirginiaTech2022}
    \item \url{http://www.jarad.me/research/presentations.html}
  \end{itemize}

  \vspace{0.1in} \pause

  \begin{center}
    {\Large
      Thank you!
    }
  \end{center}

  Other links:
  \begin{itemize}
    \item \url{http://www.jarad.me/}
    \item \url{http://www.youtube.com/jaradniemi}
  \end{itemize}
\end{frame}

\appendix
\backupbegin

\begin{frame}
\frametitle{References}
\scriptsize
\bibliography{references}
\bibliographystyle{plainnat}
\end{frame}

\end{document}
